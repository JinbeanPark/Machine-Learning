# -*- coding: utf-8 -*-
"""Fall2021-CS146-HW4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16MyM-sKxlzF_OB-X-xJng8JS9T1P1fZR
"""

"""
Name: Jinbean Park
UID: 805330751
Homework 4
"""

# To add your own Drive Run this cell.
from google.colab import drive
drive.mount('/content/drive')

"""
Author      : Te-Lin Wu, adapted from Zeyuan Chen, Yi-Chieh Wu, Sriram Sankararman
Description : Twitter
"""

import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt


from sklearn import metrics 
from sklearn.svm import SVC
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.mixture import GaussianMixture
from sklearn.metrics.cluster import adjusted_rand_score

import pandas as pd
### ========== TODO : START ========== ###
# append your own path to the tweeter_df.txt file after "/content/drive/My Drive/"
# i.e. "/content/drive/My Drive/CM146HW4/tweets_df.txt"
tweets_df = pd.read_csv("/content/drive/My Drive/CSM146/HW4/tweets_df.txt", index_col = 0)
### ========== TODO : END ========== ###

X = tweets_df.values[:,:-2]
y = tweets_df.values[:, -2]
movies = tweets_df.values[:, -1]

train_idx = np.where((movies == 1) | (movies == 3))[0]
dev_idx   = np.where(movies == 2)[0]
test_idx  = np.where(movies == 0)[0]

X_train, X_dev, X_test = X[train_idx,], X[dev_idx,], X[test_idx,]
y_train, y_dev, y_test = y[train_idx,], y[dev_idx,], y[test_idx,]

### ========== TODO : START ========== ###
# part 3.1 i: show the train and development set f1-score when C is set to 10^-3 10^-2 10^-1, 0.5, 1, 5, 10, 100, 1000
#             This can typically be done in 20 lines or so (for f1-score, just use the default settings.)
cVals = [10**-3, 10**-2, 10**-1, 0.5, 1, 5, 10, 100, 1000]
trainScore = []
devScore = []

for i in range(len(cVals)):
  model = SVC(kernel = "linear", C = cVals[i])
  model.fit(X_train, y_train)
  y_pred = model.predict(X_train)
  trainScore.append(metrics.f1_score(y_train, y_pred))
  y_pred = model.predict(X_dev)
  devScore.append(metrics.f1_score(y_dev, y_pred))

bestDevF1Score = max(devScore)
bestDevIndxC = devScore.index(bestDevF1Score)
print("The best value of C for the dev: ", cVals[bestDevIndxC])
print("The dev f1-score when using the best C: ", bestDevF1Score)
bestTrainF1Score = max(trainScore)
bestTrainIndxC = trainScore.index(bestTrainF1Score)
print("The best value of C for the train: ", cVals[bestTrainIndxC])
print("The train f1-score when using the best C: ", bestTrainF1Score)

plt.figure()
plt.plot(cVals, trainScore, 'o', label = "train f1 score")
plt.plot(cVals, devScore, 'o', label = "dev f1 score")
plt.xscale("log")
plt.legend()
plt.xlabel("values of C")
plt.ylabel("f1 score")


### ========== TODO : END ========== ###

### ========== TODO : START ========== ###
# part 3.1 ii: select the best model based on development set f1-score 
#              retrain the model on the train set
#              test the final model on the test set
#              This can typically be done in 5 lines or so

model = SVC(kernel = "linear", C = cVals[bestDevIndxC])
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
testScore = metrics.f1_score(y_test, y_pred)

print("The test f1-score when using the best C: ", testScore)


### ========== TODO : END ========== ###

def plot_scatter(embedding_2d, labels, show = True, save_as = None, title = None):
    """
    Visualize 2D data

    Parameters
    --------------------
        embedding_2d   -- numpy array of shape (n,2) samples
        labels         -- numpy array of shape (n,) labels
        show           -- optional boolean indicator on if display the visualziation, default set to True 
        save_as        -- optional string indicating where we should save the figure, default set to None
        title          -- optional string indicating what should be the title, default set to None
    --------------------
        None    
    """
    
    plt.scatter(embedding_2d[:,0], embedding_2d[:,1], c = labels) 
    if title is not None:
        plt.title(title)
    if save_as is not None:
        plt.savefig(save_as)
    if show:
        plt.show()

pca = PCA(n_components=2)
pca.fit(X)
X_embedding = pca.transform(X)

### ========== TODO : START ========== ###
# part 3.2 i: Visualize the embedding. First color the dots by positive or negative review, then by movies 
#             This can typically be done in 2 lines or so

plot_scatter(X_embedding, y, title = "Colored by positive and negative review")
plot_scatter(X_embedding, movies, title = "Colored by movies")

### ========== TODO : END ========== ###

### ========== TODO : START ========== ###
# part 3.2 ii: Color the dots by Kmeans with 4 components, random initialization, 1 iteration, random_state = 2
#              Report the adjusted rand score for both
#              This can typically be done in 5 lines or so
kmeansModel = KMeans(n_clusters = 4, init = "random", n_init = 1, random_state = 2)
kmeansModel.fit(X_embedding)
kmeansLabels = kmeansModel.labels_

plot_scatter(X_embedding, kmeansLabels, title = "Which movies Tweets refer to labeled by KMeans")
adjustedRandScore = adjusted_rand_score(movies, kmeansLabels)
print("The adjusted rand score for KMeans: ", adjustedRandScore)
### ========== TODO : END ========== ###

### ========== TODO : START ========== ###
# part 3.2 iii: Color the dots by Kmeans with 4 components, random initialization, 100 iterations, random_state = 2
#               Report the adjusted rand score for both
#               This can typically be done in 5 lines or so

kmeansModel = KMeans(n_clusters = 4, init = "random", n_init = 100, random_state = 2)
kmeansModel.fit(X_embedding)
kmeansLabels = kmeansModel.labels_

plot_scatter(X_embedding, kmeansLabels, title = "Which movies Tweets refer to labeled by KMeans")
adjustedRandScore = adjusted_rand_score(movies, kmeansLabels)
print("The adjusted rand score for KMeans: ", adjustedRandScore)
### ========== TODO : END ========== ###
